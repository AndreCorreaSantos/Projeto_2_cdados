{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e54bfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from funcoes import *\n",
    "from tqdm import tqdm #biblioteca importada para estimar o tempo de compilação do código\n",
    "pd.options.mode.chained_assignment = None\n",
    "#dados foram baixados de https://www.cryptodatadownload.com/data/binance/ --> links para download: https://www.cryptodatadownload.com/cdd/Binance_BTCUSDT_minute.csv e https://www.cryptodatadownload.com/cdd/Binance_ETHUSDT_minute.csv\n",
    "#baseado no paper: https://www.akademiabaru.com/doc/ARBMSV14_N1_P35_41.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f440f",
   "metadata": {},
   "source": [
    "O objetivo do projeto é criar um modelo que seja capaz de realizar previsões sobre a variação do preço de um cryptoativo (bitcoin) em incrementos de tempo definidos, no caso, de minuto em minuto. Após extensa pesquisa, foi encontrado um artigo (link presente nos comentarios acima), que alegava ter conseguido uma boa acurácia utilizando uma regressão logística binomial. Portanto, partindo desse documento partimos para tentar implementar o modelo estátistico proposto pelo mesmo.\n",
    "\n",
    "No documento acadêmico a técnica utilizada foi a de regressão logística binomial, de forma que a saída é 0 ou 1. 0 Indica que o valor do ativo irá cair no próximo incremento de tempo e 1 indica a subida no próximo incremento de tempo.\n",
    "\n",
    "Começamos baixando um arquivo csv contendo colunas com valores de \"open,high,low,close,Volume BTC,Volume USDT,tradecount\" para cada minuto da criptomoeda bitcoin desde 2019 e calculamos os features e o target do modelo com esse dataframe.\n",
    "\n",
    "Os features são indicadores técnicos, calculados para cada minuto (cada row do dataframe) e são funções de valores de rows anteriores do dataframe, para exemplificar, alguns são calculados com médias de preço dos últimos 12 incrementos de tempo, outros são calculados com o volume de trades no intervalo citado. Dos features escolhidos, todos são ou indicadores técnicos de \"momentum\" - que medem de diversas formas a taxa de aumento ou de queda do preço de um ativo ou são indicadores técnicos de \"trend\"- que tentam estimar tendências na variação do valor do ativo. O paper faz um ótimo trabalho de explicar a fundo cada indicador, em caso de dúvida.\n",
    "\n",
    "Já o target, que é a variação do preço do ativo (positiva, ou negativa), é calculado pela subtração do preço de fechamento (close price) do ativo em dois tempos subsequentes, ou seja, sendo P(t) o close price do ativo, o target é igual ao \"sinal\" de P(t+1) - P(t), caso essa variação seja positiva o target é 1, caso seja negativa o target é 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff224c",
   "metadata": {},
   "source": [
    "Vale notar que alguns features são calculados com base em tempos anteriores, como por exemplo, o 12_SMA (Simple moving average de 12 incrementos de tempo) é obtido em função do close price de 12 incrementos de tempo anteriores e, portanto, para as primeiras 12 rows do dataframe esse feature será Nan. Assim sendo, é utilizado o df.dropna para eliminar as linhas nas quais alguns features ainda não estão definidos. Fora isso, não existem rows com valores nulos no df, deste modo, o uso do df.dropna não diminuirá o tamanho do dataframe de forma significativa e não afetará a acurácia do modelo. Ver imagem modelo.png "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fed2f",
   "metadata": {},
   "source": [
    "Partindo para a lógica de treinamento e teste do modelo: foi definido um intervalo de 1000 incrementos de tempo de \"lookback\" para o modelo, isto é, toda regressão realizada teve seus coeficientes de regressão determinados à partir de 1000 incrementos de tempo anteriores (que equivalem à 1000 rows do dataframe). A título de exemplo, em um dataframe com 100000 dados, o modelo começa a operar na linha 1000. Ele determinará os coeficientes de regressão à partir de um fitting que utiliza os 1000 rows de features e targets anteriores e então, munido desses coeficientes ele insere os valores dos features da row em que se encontra (no caso a row 1000) e realiza uma estimativa. Ou seja, na primeira iteração (onde i = 1000) o modelo determina os coeficientes de regressão à partir das 1000 rows anteriores, e insere os valores da row 1000 na fórmula com os coeficientes de regressão encontrados e retorna a probabilidade do preço subir no próximo incremento de tempo, definimos uma linha média y = 0.5, de modo que, caso a probabilidade seja igual ou maior que 0.5 o output é igual 1 e caso a probabilidade seja menor que 0.5 o output é 0 (ver imagem grafico.png). A previsão é então inserida em uma lista que guarda os resultados produzidos pelo modelo para posteriormente ser comparada com os valores reais.\n",
    "\n",
    "Importante notar que as previsões realizadas pelo modelo NÃO são usadas pelo mesmo na determinação de coeficientes de regressão em iterações futuras e, além disso, o modelo não tem acesso a \"dados futuros\" toda previsão realizada pelo modelo é feita exclusivamente em função das últimas 1000 rows de features (por meio da lista de listas de features) e deste modo, toda vez que o modelo realiza uma previsão é como se ele de fato estivesse no minuto em questão e tentasse prever a variação do preço do ativo para o próximo minuto.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01525ff",
   "metadata": {},
   "source": [
    "Organizando dataframe de BTC para intervalos de 1 minuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bec50037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#número de rows escolhido foi de 100000, de forma a salvar tempo de processamento. Representa por volta de 69 dias. Chegamos a rodar o modelo com todas as linhas do dataframe, mas o tempo de compilação foi superior à 6 horas e, portanto, tornou-se inviável operar com um dataframe desse tamanho.\n",
    "nrows = 100000\n",
    "df = pd.read_csv(\"Binance_BTCUSDT_minute.csv\",skiprows=1,nrows=nrows) \n",
    "\n",
    "calculate_indicators(df) #chamando função que foi definida no arquivo funcoes e que tem a finalidade de calcular os features em cada row e inseri-los no proprio dataframe original.\n",
    "df = df.dropna(axis=0,how=\"any\") #retirando as linhas com valores null ou nan do dataframe, lembrando que essas serão as linhas onde alguns features ainda não possuem dados antecedentes suficientes para serem calculados.\n",
    "x,y = get_x_y(df) #chamando função que foi definida na file funcoes e que tem a finalidade de retornar duas listas, x - lista que guarda uma lista dos features para cada row e y - lista que guarda o change (target) 0 ou 1 para cada row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2c29e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98975/98975 [27:04<00:00, 60.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 69.14473351856529\n",
      "dos erros 51% são falsos positivos e 48.5% são falsos negativos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interval = 1000 #definicao do intervalo (também chamado de \"lookback\"), isto é, o número de rows que o modelo usará para determinar os coeficientes de regressão em cada iteração.\n",
    "\n",
    "falso_pos = 0\n",
    "falso_neg = 0\n",
    "\n",
    "lista_resultados = [] #iniciando variavel lista para guardar as previsões realizadas pelo modelo.\n",
    "lista_coeficientes = [] #lista que guarda os coeficientes de regressao, não é utilizada no modelo mas serve para analisar a importância de cada um.\n",
    "\n",
    "#loop que parte do intervalo, no caso row 1000 do df, e, com passo = 1, vai iterar por todo o dataframe realizando previsões do target seguindo a lógica já citada.\n",
    "for i in tqdm(range(interval,len(x))):#tqdm gera a barra de estimativa do tempo para compilar o código.\n",
    "\n",
    "    x_train,y_train = x[i-interval:i],y[i-interval:i] #selecionando o x e o y que vão ser usados no fit do modelo, para determinar os coeficientes de regressão da iteração. lembrando que estes serão sempre x[i-interval:i] e y[i-interval:i], ou seja, os ultimos 1000 valores de x e y sem contar a row atual - a row atual será usada como input para prever o target da iteração.\n",
    "    x_test = x[i] # definindo os inputs que serão usados para calcular a probabilidade do preco da btc subir ou descer proximo minuto.\n",
    "    \n",
    "    coeficientes = calc_coefs(x_train,y_train) #chamando função que foi definida no arquivo funcoes; essa função recebe uma lista de listas (x_treino) e uma lista de targets e retorna os coeficientes de regressão.\n",
    "    lista_coeficientes.append(coeficientes) #apendando os coeficientes de regressão à lista de coeficientes para poder avaliar a importância de cada feature posteriormente.\n",
    "\n",
    "    lista_resultados.append(calcula_p(x_test,coeficientes)) #chamando função que foi definida no arquivo funcoes; essa função efetua a previsão da probabilidade do preço subir ou descer no minuto seguinte (target), para tal ela coloca os features da row em que se encontra (row=i) como inputs na função logística e os coeficientes da função logistica são os que foram calculados por meio do calc_coefs()\n",
    "    \n",
    "y = y[interval:] #retirando os primeiros 1000 elementos da lista de targets para poder comparar a lista das previsões que foram realizadas pelo modelo com a lista dos valores de fato.\n",
    "x = x[interval:]\n",
    "\n",
    "acertos_btc_min = 0 #número que guardará os acertos\n",
    "\n",
    "linha_decisao = 0.5 #todas as probabilidades que o modelo definiu como acima de 0.5 são classificadas como 1 e abaixo de 0.5 como 0, lembrar da imagem da função logística.\n",
    "\n",
    "for i in range(0,len(lista_resultados)): #loop que compara as previsões realizadas pelo modelo com os valores verdadeiros para determinar a acurácia do sistema.\n",
    "    if lista_resultados[i] >= linha_decisao and y[i] == 1:\n",
    "        acertos_btc_min += 1\n",
    "    if lista_resultados[i] < linha_decisao and y[i] == 0:\n",
    "        acertos_btc_min += 1\n",
    "    if lista_resultados [i] >= linha_decisao and y[i] != 1:\n",
    "        falso_pos += 1\n",
    "    if lista_resultados [i] <= linha_decisao and y[i] != 0:\n",
    "        falso_neg += 1\n",
    "    \n",
    "falso_pos = falso_pos/(len(y)-acertos_btc_min)\n",
    "falso_neg = falso_neg/(len(y)-acertos_btc_min)\n",
    "\n",
    "print(\"acurácia: \"+str(acertos_btc_min/len(y)*100)) #dividindo número de acertos pelo tamanho da array de targets e multiplicando o resultado por 100 para determinar acurácia em %\n",
    "print(\"dos erros {:.0%} são falsos positivos e {:.1%} são falsos negativos\".format(falso_pos,falso_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae98841",
   "metadata": {},
   "source": [
    "Percebe-se, finalmente, que a acurácia de 69.144% do sistema construído é muito próxima com a acurácia de 71.4% citada pelos acadêmicos e, portanto, o modelo pode ser considerado validado.\n",
    "\n",
    "No paper são citadas duas acurácias: a maior, de 86%, usa \"in sample data\" - que não é o caso do nosso modelo. Já a menor, de 71.4%, é obtida usando somente \"out of sample data\" - que corresponde ao nosso caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38041c3f",
   "metadata": {},
   "source": [
    "Avaliando as importâncias médias de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00e51b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produto valor medio X coeficiente medio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tradecount</th>\n",
       "      <td>-0.046889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACD</th>\n",
       "      <td>0.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI</th>\n",
       "      <td>7.146344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>1.121305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_SMA</th>\n",
       "      <td>1856.730989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_EMA</th>\n",
       "      <td>-1865.272371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC</th>\n",
       "      <td>-0.000042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "tradecount    -0.046889\n",
       "MACD           0.035175\n",
       "RSI            7.146344\n",
       "SO             1.121305\n",
       "12_SMA      1856.730989\n",
       "12_EMA     -1865.272371\n",
       "ROC           -0.000042"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#transpondo a lista de coeficientes de cada iteração (lista de listas)\n",
    "trans = list(map(list, zip(*lista_coeficientes)))\n",
    "\n",
    "colunas = list(df.columns)[9:]\n",
    "\n",
    "importancias = []\n",
    "#calculando a media de cada feature e a media dos coeficiente de regressao que multiplicavam cada feature\n",
    "for i in range(0,len(colunas)):\n",
    "    media_df = np.mean(df[colunas[i]])\n",
    "    media_coef = np.mean(trans[i])\n",
    "    importancias.append(media_df*media_coef)\n",
    "\n",
    "\n",
    "import_df = pd.DataFrame(importancias,colunas)  \n",
    "print(\"produto valor medio X coeficiente medio\")\n",
    "import_df\n",
    "\n",
    "\n",
    "#coefs_import = [math.exp(np.mean(trans[0])*np.mean(df.MACD)),math.exp(np.mean(trans[1])*np.mean(df.RSI)),math.exp(np.mean(trans[2])*np.mean(df.SO)),math.exp(np.mean(trans[3])*np.mean(df[\"12_SMA\"])),math.exp(np.mean(trans[5])*np.mean(df.ROC)),math.exp(np.mean(trans[6])*np.mean(df[\"tradecount\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8285f",
   "metadata": {},
   "source": [
    "É importante notar, que no modelo de fato, todos esses produtos se tornam, na verdade, uma potência do número de Euler e, portanto, ao serem multiplicados na expressão de cálculo da probabilidade (ver figura modelo.png) todos acabam sendo somados e os valores dos features 12_SMA e 12_EMA que parecem absurdos isoladamente, tornam-se plausíveis visto que a soma de ambos (em média) é igual a aproximadamente -9, um valor mais próximo da faixa dos outros. Ademais percebe-se dessa análise que os features de maior importância são o RSI, o SO e a soma de 12_SMA e 12_EMA. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d699d777ee69141fba663d9f9c6d16862b3efc9df34970effb09a39e215af04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
